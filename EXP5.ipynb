{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbcb6c7f",
   "metadata": {},
   "source": [
    "## 가위바위보 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "052623a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bceb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fa1f8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAFAElEQVR4nG1W2a4kORGNzXYuddVqwQjBr/IT8GNIiE8YMSMuM2pqyUovsfDg6svViHiwUl6OTywnnPjnv/wVEZmIGYmImRkJCYgIABiQGXPOOWdCNLM3DotISyEu3YNy4Zxr17/94+/X24OEt20R/G4AMMdpc5K+z7k7fN+D7gAA4AAxl8YYZhZhGEhE9H8R/wdKxMzzZER8MECPiAAAhnDV2p7Wh5sRojDSb5h+QM8PotfF7g4AIgLoABDhEEbgEaFjPO/30WvoEIQs8jozx89wk8hciggzc3dEpIAAc3cziwgEb+183O7WO4Qn4S0n+cQRPlP+wAUAVW2thbuIGFtEuHtAIIK7aq+P+xXCEuOS5TIT9TmIn2M6cc2s9/58PkfvRLTvFBER6kZERBG99+fzQQQivC3lsq3yCS5+k6iIiAj3GGPUWpU5peT7xSHcA+i1Y96aUkosJctSEk0fiUhERGRGUFURsfc+xmDmbdtyzhExxjhbU/eybrV1g3CI9/f3mZLL5bLv+5KymNkE6n2oKgBkSbkkd2fmKQEi2rYNIkopbSgR8dAgNIfxrLV3AGDmUsqSMgDIh7+tteM4zGxftwvuZsbMEdFaiwgRQYCIePaOiCEZSdTher2frQMxp7yua1qKu8tHfqbXrTVX66N9/fp1lv0YAwBSSuHeWrNQYMI21v1i7t9u9z6slJKk5GUVzmMofaglpbTv+7quAFBrVVX/bojIzCKCiCPAg6uqBzbzx3k6Iuecl8KU3GGMIVMqCJBSEpFSSq+tj1ZrNTNBctec82w6iBggIKkNrWP0MVpXlsyS87oGQhvd1WVWsgEAIBGllBgpl9RaO8/Th0ZYKcXMllKIKAiZ5XnW2toY1k1TSkS0LnsE9KaE/ir+KbspSiHOOTPzcRyjNned7ieRGVkkUtU6VFXdgEtyhFSyuZIZCclhgIiEyEAISIFuAWbrkpc9uvfb/QHj9C1AqML4k8B5v/3Aoc92O84Ldja5pM2GAkANP4e9YhofkieCcAJ8PJ45y5cvX5jxdtyO+0N1rOt6IKoHsiDK5zZkZrOEIkLUBgIFoiMyQLgzYIADhrtnSW/7BdyO+vA+FOkZjiyZRUSWZVFgkiXn7NodKCIwXkynkmenDwSM8GVZej3q+VySvK3bIjy0A4C6gY9AEhQR2fcMJIl5qvHF1F9vAyCizxgAIICOERoEwQKZuORFkdw9ibTRzzYkzrKswqwAo/d5brYgcTVEdAxEMogAdEQBrGd/27e9CIb66Ai+kiAHZoLKVuskRYgM0XUgoserscmsJAAgYgB2BAKICIbAgNH0eftPaL2sWXKy0auSmQUSRKhqIBOREPbeZkwjQsA1ghDRAhyAX7iIiPf7cf/2y+3Xf++J0x9/4J4f9+svbDlnESFk7CPnkcoqIq4WaC/69XkKY60VPZZlC0LORSSnshzPM6XCQP/88cfbr98W4eftetZ2fxz3x3G2Oh+usOHatyWXJOB2Hg85bvetLISo6q01tQC0OtQ9SVkuSTah33/Z//C7ryXnt22/MkTY7PYAwEjCJExhihCMQUTy/vNPb/sFWbp1B0LJQNh1uI49pSDctu3rlhPG4/EgRMlJVccYZt3dmVASJ5agAABCSIz0r59+Pp/P2Uz7MGYmyYZkiE54fxzX49nVr9fr+/u7mpEkZJl/AmFuZq5DtbsOcENEYfov/lzfweVeM+IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=28x28 at 0x7FDB23D6CFA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_path = os.getenv('HOME')+'/aiffel/rock_scissor_paper/scissor/0.jpg'\n",
    "img = Image.open(image_path)\n",
    "img.show()\n",
    "ima_size = img.size\n",
    "print(ima_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21d1b562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac1cf2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "#28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfeed147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a967163a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[1])\n",
    "print('라벨: ', y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89e4fbde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                25632     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 31,050\n",
      "Trainable params: 31,050\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# model의 입력/출력부에 특히 유의해 주세요. \n",
    "#가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "#(흑백->칼라, 레이블 10->3)\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad0477cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 28, 28, 3) (300,)\n",
      "Epoch 1/100\n",
      "10/10 [==============================] - 1s 21ms/step - loss: 2.0532 - accuracy: 0.2433\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 1.2121 - accuracy: 0.3633\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.0774 - accuracy: 0.3967\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.0074 - accuracy: 0.4433\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.9594 - accuracy: 0.5233\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8990 - accuracy: 0.6233\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.8667 - accuracy: 0.6300\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8420 - accuracy: 0.6533\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.7534 - accuracy: 0.7667\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 25ms/step - loss: 0.7040 - accuracy: 0.7567\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.6563 - accuracy: 0.7533\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5948 - accuracy: 0.8100\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5439 - accuracy: 0.8433\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.5972 - accuracy: 0.7400\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4928 - accuracy: 0.8167\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4417 - accuracy: 0.8833\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.4216 - accuracy: 0.8667\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.4263 - accuracy: 0.8167\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3508 - accuracy: 0.9167\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3215 - accuracy: 0.9267\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.3162 - accuracy: 0.9167\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.2922 - accuracy: 0.9200\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2886 - accuracy: 0.8967\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2870 - accuracy: 0.9000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2356 - accuracy: 0.9433\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2300 - accuracy: 0.9300\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1920 - accuracy: 0.9633\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1876 - accuracy: 0.9633\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1910 - accuracy: 0.9700\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1669 - accuracy: 0.9633\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1721 - accuracy: 0.9600\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1543 - accuracy: 0.9667\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1548 - accuracy: 0.9633\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1816 - accuracy: 0.9500\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1620 - accuracy: 0.9700\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.1290 - accuracy: 0.9733\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1229 - accuracy: 0.9700\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.1211 - accuracy: 0.9633\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1071 - accuracy: 0.9800\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.1031 - accuracy: 0.9833\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0974 - accuracy: 0.9800\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.1127 - accuracy: 0.9633\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0869 - accuracy: 0.9767\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0798 - accuracy: 0.9833\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0727 - accuracy: 0.9833\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0683 - accuracy: 0.9833\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0678 - accuracy: 0.9833\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0791 - accuracy: 0.9767\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0628 - accuracy: 0.9800\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0591 - accuracy: 0.9933\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0590 - accuracy: 0.9800\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0639 - accuracy: 0.9900\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0480 - accuracy: 0.9900\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0438 - accuracy: 0.9833\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0382 - accuracy: 0.9900\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0383 - accuracy: 0.9967\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0354 - accuracy: 0.9967\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0339 - accuracy: 0.9900\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0362 - accuracy: 0.9933\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0296 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0300 - accuracy: 0.9933\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0269 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0228 - accuracy: 0.9967\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0220 - accuracy: 0.9967\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.0195 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0140 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0131 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0119 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0114 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0107 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0086 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0073 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0078 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0061 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 17ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 18ms/step - loss: 0.0058 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0046 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0045 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdb00ccf130>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 딥러닝 네트워크 학습시키기\n",
    "print(x_train_norm.shape, y_train.shape)\n",
    "#x_train_reshaped.shape\n",
    "x_train_reshaped=x_train_norm.reshape(-1, 28, 28, 3)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_reshaped, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "613742cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만들기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "x_test_reshaped=x_test_norm.reshape(-1, 28, 28, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b55da8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 0.0000e+00 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 학습된 model을 test 데이터에 적용함\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5330ab",
   "metadata": {},
   "source": [
    "### 평가결과: Loss는 0.0 이고, 정확도도 100% 임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a149ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65e469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6026e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58b6ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
